{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspired by https://github.com/maetshju/gsoc2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Flux [587475ba-b771-5e3f-ad9e-33799f191a9c]\n",
      "└ @ Base loading.jl:1260\n"
     ]
    }
   ],
   "source": [
    "using Flux: onehotbatch\n",
    "using DSP\n",
    "\n",
    "using FileIO: load, save, loadstreaming, savestreaming\n",
    "import LibSndFile\n",
    "\n",
    "using MFCC\n",
    "using Plots\n",
    "using BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pwd()*\"/Datasets/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav\")\n",
    "\n",
    "FRAME_LENGTH = 0.025 # ms\n",
    "FRAME_INTERVAL = 0.010 # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getFeatures"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2 \n",
    "\"\"\"\n",
    "    getFeatures( wavName )\n",
    "Extracts Mel filterbanks and associated labels from `wavName`, fortunately ravdess incorporates labels into the filename\n",
    "\"\"\"\n",
    "function getFeatures( wavName )\n",
    "    \n",
    "    samps, sr = load(wavName)\n",
    "    samps = vec(samps)\n",
    "    \n",
    "    #.+ eps to avoid Inf's and NaN's\n",
    "    samps.+=eps()\n",
    "\n",
    "    #Kind of handles resampling! Consider lowering quality of training data if accuracy is too off\n",
    "    mfccs, _, _ = mfcc(samps, sr, :rasta; wintime=FRAME_LENGTH, steptime=FRAME_INTERVAL)\n",
    "    \n",
    "    #Directories might be missing on Repo\n",
    "    #GET 06!!!\n",
    "    #emotion = 03-01-06-01-02-01-12.wav\n",
    "    emotion = parse(Float64,(wavName[82:83]))\n",
    "    \n",
    "    #plot(mfccs)\n",
    "    #print(mfccs)\n",
    "    \n",
    "    #use this if you want to use deltas as additional features\n",
    "    #use this if you're not going to use a Recurrent Network\n",
    "    #mfccDeltas = deltas(mfccs, 2)\n",
    "    #features = hcat(mfccs, mfccDeltas)\n",
    "    \n",
    "    #We're using a Recurrent Network\n",
    "    features = mfccs\n",
    "    \n",
    "    #print(size(features))\n",
    "    \n",
    "    \n",
    "    labels = fill( emotion, length(features) )\n",
    "    \n",
    "    toReturn = (features, labels)\n",
    "    return toReturn\n",
    "end\n",
    "\n",
    "#typeof(getFeatures(\"Datasets/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createData"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    createData(data_dir, out_dir)\n",
    "Extracts data from files in `data_dir` and saves results in `out_dir`.\n",
    "\"\"\"\n",
    "function createData(data_dir, out_dir)\n",
    "    for (root, dirs, files) in walkdir(data_dir)\n",
    "        #println(files)\n",
    "        \n",
    "        \n",
    "        wavFiles = [x for x in files if occursin(\"wav\",x)]\n",
    "        \n",
    "        one_dir_up = basename(root)\n",
    "        #println(wavFiles)\n",
    "                    \n",
    "        for wavFile in wavFiles\n",
    "            wavPath = joinpath(root, wavFile)\n",
    "            #println(wavPath)\n",
    "            #return\n",
    "            x, y = getFeatures(wavPath)\n",
    "            classes = [n for n in 1:8]\n",
    "            #print(classes)\n",
    "            y = onehotbatch(y, classes)'\n",
    "                        \n",
    "            base, _ = splitext(wavFile)\n",
    "            #print(one_dir_up * \"-\" * base * \".bson\")\n",
    "            dat_name = one_dir_up * \"-\" * base * \".bson\"\n",
    "            dat_path = joinpath(out_dir, dat_name)\n",
    "            #println(dat_path)\n",
    "            BSON.@save dat_path x y\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "createData(\"Datasets/ravdess-emotional-speech-audio\",\"Datasets/ravdess-processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createData(TRAINING_DATA_DIR, TRAINING_OUT_DIR)\n",
    "#createData(TEST_DATA_DIR, TEST_OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
