{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspired by https://github.com/maetshju/gsoc2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet: param, param0\n",
    "using DSP\n",
    "\n",
    "using FileIO: load, save, loadstreaming, savestreaming\n",
    "import LibSndFile\n",
    "\n",
    "using MFCC\n",
    "using Plots\n",
    "using BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(pwd()*\"/Datasets/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav\")\n",
    "\n",
    "FRAME_LENGTH = 0.025 # ms\n",
    "FRAME_INTERVAL = 0.010 # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classes1_3 (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 and 3\n",
    "onehotencoding(x) = (x==1) ? UInt8.([1;0]) : UInt8.([0;1])\n",
    "\n",
    "encode1_3(x) = (x==1) ? 1 : 2\n",
    "\n",
    "classes1_3(x) = (x==1) ? 1 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classes2_3 (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 and 3\n",
    "onehotencoding(x) = (x==2) ? UInt8.([1;0]) : UInt8.([0;1])\n",
    "\n",
    "encode2_3(x) = (x==2) ? 1 : 2\n",
    "\n",
    "classes2_3(x) = (x==2) ? 1 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classes1_3 (generic function with 1 method)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "replaceClasses (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaceClasses(x) = classes2_3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getFeatures"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2 \n",
    "\"\"\"\n",
    "    getFeatures( wavName )\n",
    "Extracts Mel filterbanks and associated labels from `wavName`, fortunately ravdess incorporates labels into the filename\n",
    "\"\"\"\n",
    "function getFeatures( wavName )\n",
    "    \n",
    "    samps, sr = load(wavName)\n",
    "    samps = vec(samps)\n",
    "    \n",
    "    #.+ eps to avoid Inf's and NaN's\n",
    "    samps.+=eps()\n",
    "\n",
    "    #Kind of handles resampling! Consider lowering quality of training data if accuracy is too off\n",
    "    mfccs, _, _ = mfcc(samps, sr, :rasta; wintime=FRAME_LENGTH, steptime=FRAME_INTERVAL)\n",
    "    \n",
    "    #Directories might be missing on Repo\n",
    "    #GET 06!!!\n",
    "    #emotion = 03-01-06-01-02-01-12.wav\n",
    "    emotion = parse(Float64,(wavName[82:83]))\n",
    "    \n",
    "    #plot(mfccs)\n",
    "    #print(mfccs)\n",
    "    \n",
    "    \n",
    "    #We're using a Recurrent Network\n",
    "    \n",
    "    #print()\n",
    "    \n",
    "    #13 Features\n",
    "    #features = mfccs\n",
    "    \n",
    "    #use this if you want to use deltas as additional features\n",
    "    mfccDeltas = deltas(mfccs, 2)\n",
    "    features = hcat(mfccs, mfccDeltas)\n",
    "    #println(size(features))\n",
    "    \n",
    "    #print(features[1])\n",
    "    \n",
    "    \n",
    "    #labels = fill( onehotencoding(emotion), size(features)[1] )\n",
    "    labels = fill( replaceClasses(emotion), size(features)[1] )\n",
    "    \n",
    "    \n",
    "    toReturn = (Float32.(features), UInt8.(labels)) \n",
    "    return toReturn\n",
    "end\n",
    "\n",
    "#typeof(getFeatures(\"Datasets/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createData"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    createData(data_dir, out_dir)\n",
    "Extracts data from files in `data_dir` and saves results in `out_dir`.\n",
    "\"\"\"\n",
    "function createData(data_dir, out_dir)\n",
    "    #println(\"WARNING NOT SAVING\")\n",
    "    for (root, dirs, files) in walkdir(data_dir)\n",
    "        #println(files)\n",
    "        \n",
    "        wavFiles = [x for x in files if occursin(\"wav\",x)]\n",
    "        \n",
    "        one_dir_up = basename(root)\n",
    "        #println(wavFiles)\n",
    "                    \n",
    "        for wavFile in wavFiles\n",
    "            wavPath = joinpath(root, wavFile)\n",
    "            #println(wavPath)\n",
    "            #return\n",
    "            \n",
    "            x, y = getFeatures(wavPath)\n",
    "                        \n",
    "            #x = Float32.(x)\n",
    "            #println(summary(x))\n",
    "            #y = UInt8.(replaceClasses.(y))\n",
    "            #println(summary(y))\n",
    "                        \n",
    "            \n",
    "            #classes = [n for n in 1:8]\n",
    "                        \n",
    "            #break\n",
    "            #print(classes)\n",
    "                        \n",
    "            #FOR FLUX\n",
    "            #y = onehotbatch(y, classes)'\n",
    "            #no onehot encoding this time\n",
    "            #y = \n",
    "            \n",
    "            #FOR KNET\n",
    "                        \n",
    "            #Keep as is\n",
    "                        \n",
    "            base, _ = splitext(wavFile)\n",
    "            #print(one_dir_up * \"-\" * base * \".bson\")\n",
    "            dat_name = one_dir_up * \"-\" * base * \".bson\"\n",
    "            dat_path = joinpath(out_dir, dat_name)\n",
    "            #println(dat_path)\n",
    "                        \n",
    "            #println(y)\n",
    "            #return\n",
    "            BSON.@save dat_path x y\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94.329808 seconds (320.81 M allocations: 29.725 GiB, 6.94% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time createData(\"Datasets/ravdess-emotional-speech-audio\",\"Datasets/ravdess-26-features-2-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createData(TRAINING_DATA_DIR, TRAINING_OUT_DIR)\n",
    "#createData(TEST_DATA_DIR, TEST_OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Float32[-143.93388 -15.416435 … -0.89059263 -0.38944596; -131.18521 -15.478297 … -0.8413835 -1.1602328; … ; -97.957535 -8.081757 … 1.8839778 0.82921773; -96.52068 -8.230402 … 1.090286 2.860385], UInt8[0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02  …  0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = getFeatures(\"Datasets/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_12/03-01-03-01-02-01-12.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO IN PREPROCESS:\n",
    "\n",
    "1. Change Features to be a Array{Float32, 2} (Done?)\n",
    "2. Label Classes Properly (Also Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: gpu not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: gpu not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[1]:1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
