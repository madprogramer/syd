Syd is an Intelligent User Interface which recomends music based on the user's preferences and current mood. 
Currently it's just a school project, I'm aiming for a design which is highly configurable both for general users and for anyone interested in making modifications.

Syd is planned to have a number of components:

1. A Voice Synthesis Module
2. A Voice/Speech Recognition Module
3. An Emotion/Mood Recognizing Module
4. A "Cognitive" Module (which will likely just be limited to understanding simple commands that have been fed in from the voice/speech recognizer and emotion/mood recognizer )
5. A Module for Browsing Music from a Platform/ different Platforms
6. A Song Recognizing Module (for songs that Syd has learned)
7. A Set of Modules for Analysing Music (genre, artists, rythm etc.)
8. A Module for Associating Songs which are similar (to later suggest)
9. An Emotional Feedback Module (which can be thought of as Syd's own mood. It decides whether to promote the user's current mood or attempt to change it. An example could be playing cheery songs if the user is happy, or playing meditative music if the user is angry.)
10. (Optionally) A Face Recognition module to add another modality for detecting the user's mood.
